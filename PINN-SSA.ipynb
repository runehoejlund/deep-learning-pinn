{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e6e09d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9135db97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "rcParams.update({\n",
    "    \"font.size\": 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "922f1608",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import InterpolatedUnivariateSpline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f0ad8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssa_v = np.genfromtxt('./ssa/compare_data_output.csv')[1:, :]\n",
    "b_val = ssa_v[:, 0]\n",
    "h_val = ssa_v[:, 1]\n",
    "u_val = ssa_v[:, 2]\n",
    "xh_val = ssa_v[:, 3]\n",
    "xu_val = ssa_v[:, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "544be432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.345833636298257"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xh_val[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0daa47c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_int = InterpolatedUnivariateSpline(xh_val, b_val)\n",
    "b_x_int = b_int.derivative(n=1)\n",
    "h_int = InterpolatedUnivariateSpline(xh_val, h_val)\n",
    "h_x_int = h_int.derivative(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "925bf836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def b_x(x):\n",
    "    if type(x) is torch.Tensor:\n",
    "        x = x.detach()\n",
    "    return torch.tensor(b_x_int(x)).float()\n",
    "\n",
    "def h_x(x):\n",
    "    if type(x) is torch.Tensor:\n",
    "        x = x.detach()\n",
    "    return torch.tensor(h_x_int(x)).float()\n",
    "\n",
    "def b(x):\n",
    "    if type(x) is torch.Tensor:\n",
    "        x = x.detach()\n",
    "    return torch.tensor(b_int(x)).float()\n",
    "\n",
    "def h(x):\n",
    "    if type(x) is torch.Tensor:\n",
    "        x = x.detach()\n",
    "    return torch.tensor(h_int(x)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9177621d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_b0 = torch.tensor(0).reshape(-1, 1).float()\n",
    "u_b0 = torch.tensor(0).reshape(-1, 1).float()\n",
    "x_b1 = torch.tensor(xh_val[-1]).reshape(-1, 1).float()\n",
    "x_b1.requires_grad=True\n",
    "ux_b1 = torch.tensor(19.6523087).reshape(-1, 1).float()\n",
    "x = torch.tensor(xu_val, requires_grad=True).reshape(-1, 1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "575a97ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensional parameters\n",
    "eps = 0.002587853191\n",
    "c_hat = 0.8501309976\n",
    "m = 3\n",
    "n = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa8fb52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,\n",
    "        N_in, N_out, N_hid,\n",
    "        N_layers=4,\n",
    "        loss_func=nn.MSELoss(),\n",
    "        LEARNING_RATE = 0.001,\n",
    "        optimizer = optim.Adam,\n",
    "        act_func=nn.Sigmoid()\n",
    "                ):\n",
    "        \n",
    "        super(Net, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "                nn.Linear(in_features=N_in,\n",
    "                    out_features=N_hid,\n",
    "                    bias=True),\n",
    "                act_func,\n",
    "                *(nn.Linear(in_features=N_hid,\n",
    "                    out_features=N_hid,\n",
    "                    bias=True), act_func)*(N_layers - 1),\n",
    "                nn.Linear(in_features=N_hid,\n",
    "                    out_features=N_out,\n",
    "                    bias=True)\n",
    "            )\n",
    "        \n",
    "        self.loss_func = loss_func\n",
    "        self.optimizer = optimizer(self.parameters(), lr=LEARNING_RATE)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "    \n",
    "    def PDE(self, x, h, h_x, b_x):\n",
    "        # Evaluate network and derivatives\n",
    "        u_hat = self.forward(x)\n",
    "        u_x_hat = torch.autograd.grad(u_hat, x, torch.ones(x.shape), create_graph=True)[0]\n",
    "        u_xx_hat = torch.autograd.grad(u_x_hat, x, torch.ones(x.shape), create_graph=True)[0]\n",
    "        \n",
    "        # Calculate terms\n",
    "        prefactor = 4*eps\n",
    "        extensional_term1 = h_x(x) * torch.abs(u_x_hat)**(1/3-1) * u_x_hat\n",
    "        extensional_term2 = h(x)/3*torch.abs(u_x_hat)**(1/3-2)*u_xx_hat\n",
    "        extensional = prefactor * (extensional_term1 + extensional_term2)\n",
    "        basal = c_hat * torch.abs(u_hat)**(1/3-1)*u_hat\n",
    "        driving = h(x) * (h_x(x) - b_x(x))\n",
    "        \n",
    "        pde = extensional - basal - driving\n",
    "        return pde\n",
    "    \n",
    "    def loss_dirichlet(self, x_b0, u_b0):\n",
    "        u_b0_hat = self.forward(x_b0)\n",
    "        loss_b0 = self.loss_func(u_b0, u_b0_hat.reshape(u_b0.shape))\n",
    "        return loss_b0\n",
    "    \n",
    "    def loss_neumann(self, x_b1, ux_b1):\n",
    "        u_b1_hat = self.forward(x_b1)\n",
    "        ux_b1_hat = torch.autograd.grad(u_b1_hat, x_b1, torch.ones(x_b1.shape), create_graph=True)[0]\n",
    "        loss_b1 = self.loss_func(ux_b1, ux_b1_hat.reshape(ux_b1.shape))\n",
    "        return loss_b1\n",
    "        \n",
    "        \n",
    "    def loss_PDE(self, x, h, h_x, b_x):\n",
    "        pde = self.PDE(x, h, h_x, b_x)\n",
    "        loss = self.loss_func(pde, torch.zeros(pde.shape, requires_grad=True))\n",
    "        return loss\n",
    "    \n",
    "    def loss(self, x, h, h_x, b_x, x_b0, x_b1, u_b0, ux_b1):\n",
    "        loss = self.loss_PDE(x, h, h_x, b_x) + self.loss_dirichlet(x_b0, u_b0) + self.loss_neumann(x_b1, ux_b1)\n",
    "        return loss\n",
    "    \n",
    "    def step(self, x, h, h_x, b_x, x_b0, x_b1, u_b0, ux_b1):\n",
    "        self.train()\n",
    "        self.optimizer.zero_grad()\n",
    "        loss = self.loss(x, h, h_x, b_x, x_b0, x_b1, u_b0, ux_b1)\n",
    "        loss.backward(retain_graph=True)\n",
    "        self.optimizer.step()\n",
    "        self.eval()\n",
    "        return self.loss_PDE(x, h, h_x, b_x), self.loss_dirichlet(x_b0, u_b0), self.loss_neumann(x_b1, ux_b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3053b0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_net(net, u, x):\n",
    "    u = torch.tensor(u).reshape(-1, 1)\n",
    "    u_hat = net(x).detach().reshape(-1,1)\n",
    "    MSE = torch.mean((u - u_hat)**2)\n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2b80f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress(i, total):\n",
    "    print(\"\\r\", '{:.2f}% '.format((i+1)*100/total), end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275c7b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 65.78% "
     ]
    }
   ],
   "source": [
    "loss_pde = []\n",
    "loss_neumann = []\n",
    "loss_dirichlet = []\n",
    "loss_data = []\n",
    "lam = []\n",
    "loss_epochs = []\n",
    "epochs = 20000\n",
    "net = Net(N_in=1, N_out=1, N_hid=20, N_layers=2)\n",
    "for e in range(epochs):\n",
    "    _loss_pde, _loss_dirichlet, _loss_neumann = net.step(x, h, h_x, b_x, x_b0, x_b1, u_b0, ux_b1)\n",
    "    loss_pde.append(_loss_pde.detach())\n",
    "    loss_dirichlet.append(_loss_dirichlet.detach())\n",
    "    loss_neumann.append(_loss_neumann.detach())\n",
    "\n",
    "    loss_data.append(eval_net(net, u_val, x))\n",
    "    progress(e, epochs)\n",
    "    #if (e+1)%200 == 0:\n",
    "    #    print('Epoch: {:d}. log Data loss: {:.2f}. log training loss: {:.2f}'.format(e+1, torch.log(loss_data[-1]), torch.log(sum(loss[-1]))))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf61d59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "ax.semilogy(loss_pde, label='PDE loss')\n",
    "ax.semilogy(loss_dirichlet, label='Dirichlet loss')\n",
    "ax.semilogy(loss_neumann, label='Neumann loss')\n",
    "ax.semilogy(loss_data, label='Evaluation loss')\n",
    "ax.legend()\n",
    "ax.set_ylabel('MSE')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.grid()\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c319733",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xu_val, net(x).detach())\n",
    "plt.plot(xu_val, u_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e1ab81b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.149709127114217"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(u_val[-1]-u_val[-2])/(xu_val[-1]-xu_val[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8a5e77af",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_b1_hat = net.forward(x_b1)\n",
    "ux_b1_hat = torch.autograd.grad(u_b1_hat, x_b1, torch.ones(x_b1.shape), create_graph=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5d62c06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0240]], grad_fn=<TBackward>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ux_b1_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813d6a7a",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
